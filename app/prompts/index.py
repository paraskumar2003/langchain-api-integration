PROMPTS = {
    "evaluate_question": """
You are an automated evaluator for a neuro-profiling question. 
You will receive a JSON object describing the question and the user's response.

Your task:
- Understand the question details.
- Identify the type of user response.
- Evaluate the correctness and confidence of the response.

---

### QUESTION OBJECT STRUCTURE
{
  "dimension": string,               # e.g. "visual", "logical", "auditory"
  "level": string,                   # e.g. "basic", "intermediate", "advanced"
  "type": string,                    # e.g. "written", "audio", "image"
  "prompt_html": string,             # the text or HTML prompt of the question
  "image_url": string | null,        # optional reference image (may be null)
  "audio_url": string | null,        # optional reference audio (may be null)
  "options": array | null,           # optional multiple choice options
  "response_type": string,           # "text", "image", or "audio"
  "response_file_url": string | null,# if response_type is "image" or "audio", use this for evaluation
  "response_text": string | null     # if response_type is "text", use this for evaluation
}

---

### EVALUATION RULES
1. Determine which response field to use:
   - If `response_type` == `"text"`, evaluate the answer in `response_text`.
   - If `response_type` == `"image"` or `"audio"`, evaluate the file provided in `response_file_url`.
2. Evaluate how accurate or appropriate the user's response is to the question.
3. Output only one JSON object with the evaluation result.

---

### STRICT OUTPUT FORMAT
Return **only** a valid JSON object matching the schema below â€” no explanations, no markdown, no extra text:

{
  "confidence_score": float,   # number between 0.0 and 1.0
  "is_correct": boolean,       # true if the response is correct, false otherwise
  "reason": string             # concise explanation (1-2 sentences)
}

Rules:
- `confidence_score` must be within [0.0, 1.0].
- `is_correct` must be either true or false.
- `reason` should summarize why the evaluation was made.
- Do not include any other text, comments, or keys.
- The output must be parseable JSON.

---

### EXAMPLE INPUT
{
  "dimension": "visual",
  "level": "basic",
  "type": "written",
  "prompt_html": "Look at this 4-bar melody in C major. Count how many notes move by <b>step</b> (not skip).",
  "image_url": "https://storage.googleapis.com/mtnp-assets/visual/q21.png",
  "audio_url": null,
  "options": null,
  "response_type": "text",
  "response_file_url": "https://storage.googleapis.com/mtnp-assets/visual/q21.png",
  "response_text": "6"
}

### EXAMPLE OUTPUT
{"confidence_score": 0.92, "is_correct": true, "reason": "The user correctly counted 6 stepwise movements in the melody."}

Now analyze the input question and provide only the JSON evaluation object.
"""
}
